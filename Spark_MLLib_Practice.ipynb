{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark MLLib 机器学习库常用算法实践\n",
    "本模块数据挖掘算法实践涵盖：\n",
    "1. 分类&回归\n",
    "2. 聚类\n",
    "3. 降维\n",
    "4. 特征提取\n",
    "5. 关联规则\n",
    "6. 基于协同过滤的算法推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('init complete\\xef\\xbc\\x9asc = ', <SparkContext master=local appName=wordCount>)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time         : 2017/12/26 13:32\n",
    "# @Author       : zenghao\n",
    "\n",
    "from pyspark import SparkContext, SparkConf # 导入相关工具包\n",
    "\n",
    "# 初始化Spark上下文\n",
    "# local为本地调试模式，具体集群方式参照http://spark.apache.org/docs/latest/cluster-overview.html\n",
    "conf = SparkConf().setAppName(\"Spark_MLLib_Practice\").setMaster(\"local\") \n",
    "sc = SparkContext(conf=conf)\n",
    "print (\"init complete：sc = \", sc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark MLLib基本数据类型\n",
    "- 关于Spark MLLib 的常用数据类型介绍可参考http://spark.apache.org/docs/latest/mllib-statistics.html\n",
    "- Spark MLLib 涵盖的常用数据类型包括：\n",
    "1. 本地向量集\n",
    "    1. 密集型数据集（dense）\n",
    "    2. 稀疏型数据集（sparse）\n",
    "2. 向量标签\n",
    "3. 本地矩阵\n",
    "4. 分布式矩阵\n",
    "    1. 行矩阵\n",
    "    2. 带有行索引的行矩阵\n",
    "    3. 坐标矩阵\n",
    "    4. 块矩阵\t\t\t\n",
    "\n",
    "> 下面先通过运行下面实例来熟悉这些常用API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2.   20.  200.]\n",
      "[  1.00000000e+00   1.00000000e+02   1.00000000e+04]\n",
      "[ 3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "mat = sc.parallelize(\n",
    "    [np.array([1.0, 10.0, 100.0]), np.array([2.0, 20.0, 200.0]), np.array([3.0, 30.0, 300.0])]\n",
    ")  # an RDD of Vectors\n",
    "\n",
    "\"\"\"\n",
    "colStats() returns an instance of MultivariateStatisticalSummary,\n",
    "which contains the column-wise max, min, mean, variance, and number of nonzeros, as well as the total count.\n",
    "\"\"\"\n",
    "# Compute column summary statistics.\n",
    "summary = Statistics.colStats(mat)\n",
    "print(summary.mean())  # a dense vector containing the mean value for each column\n",
    "print(summary.variance())  # column-wise variance\n",
    "print(summary.numNonzeros())  # number of nonzeros in each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation is: 0.850028676877\n",
      "[[ 1.          0.97888347  0.99038957]\n",
      " [ 0.97888347  1.          0.99774832]\n",
      " [ 0.99038957  0.99774832  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Statistics provides methods to calculate correlations between series. \n",
    "Depending on the type of input, two RDD[Double]s or an RDD[Vector], \n",
    "the output will be a Double or the correlation Matrix respectively.\n",
    "\"\"\"\n",
    "\n",
    "seriesX = sc.parallelize([1.0, 2.0, 3.0, 3.0, 5.0])  # a series\n",
    "# seriesY must have the same number of partitions and cardinality as seriesX\n",
    "seriesY = sc.parallelize([11.0, 22.0, 33.0, 33.0, 555.0])\n",
    "\n",
    "# Compute the correlation using Pearson's method. Enter \"spearman\" for Spearman's method.\n",
    "# If a method is not specified, Pearson's method will be used by default.\n",
    "print(\"Correlation is: \" + str(Statistics.corr(seriesX, seriesY, method=\"pearson\")))\n",
    "\n",
    "data = sc.parallelize(\n",
    "    [np.array([1.0, 10.0, 100.0]), np.array([2.0, 20.0, 200.0]), np.array([5.0, 33.0, 366.0])]\n",
    ")  # an RDD of Vectors\n",
    "\n",
    "# calculate the correlation matrix using Pearson's method. Use \"spearman\" for Spearman's method.\n",
    "# If a method is not specified, Pearson's method will be used by default.\n",
    "print(Statistics.corr(data, method=\"pearson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi squared test summary:\n",
      "method: pearson\n",
      "degrees of freedom = 4 \n",
      "statistic = 0.12499999999999999 \n",
      "pValue = 0.998126379239318 \n",
      "No presumption against null hypothesis: observed follows the same distribution as expected..\n",
      "\n",
      "Chi squared test summary:\n",
      "method: pearson\n",
      "degrees of freedom = 2 \n",
      "statistic = 0.14141414141414144 \n",
      "pValue = 0.931734784568187 \n",
      "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent..\n",
      "\n",
      "Column 1:\n",
      "Chi squared test summary:\n",
      "method: pearson\n",
      "degrees of freedom = 0 \n",
      "statistic = 0.0 \n",
      "pValue = 1.0 \n",
      "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent..\n",
      "Column 2:\n",
      "Chi squared test summary:\n",
      "method: pearson\n",
      "degrees of freedom = 0 \n",
      "statistic = 0.0 \n",
      "pValue = 1.0 \n",
      "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent..\n",
      "Column 3:\n",
      "Chi squared test summary:\n",
      "method: pearson\n",
      "degrees of freedom = 0 \n",
      "statistic = 0.0 \n",
      "pValue = 1.0 \n",
      "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent..\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Matrices, Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "vec = Vectors.dense(0.1, 0.15, 0.2, 0.3, 0.25)  # a vector composed of the frequencies of events\n",
    "\n",
    "# compute the goodness of fit. If a second vector to test against\n",
    "# is not supplied as a parameter, the test runs against a uniform distribution.\n",
    "goodnessOfFitTestResult = Statistics.chiSqTest(vec)\n",
    "\n",
    "# summary of the test including the p-value, degrees of freedom,\n",
    "# test statistic, the method used, and the null hypothesis.\n",
    "print(\"%s\\n\" % goodnessOfFitTestResult)\n",
    "\n",
    "mat = Matrices.dense(3, 2, [1.0, 3.0, 5.0, 2.0, 4.0, 6.0])  # a contingency matrix\n",
    "\n",
    "# conduct Pearson's independence test on the input contingency matrix\n",
    "independenceTestResult = Statistics.chiSqTest(mat)\n",
    "\n",
    "# summary of the test including the p-value, degrees of freedom,\n",
    "# test statistic, the method used, and the null hypothesis.\n",
    "print(\"%s\\n\" % independenceTestResult)\n",
    "\n",
    "obs = sc.parallelize(\n",
    "    [LabeledPoint(1.0, [1.0, 0.0, 3.0]),\n",
    "     LabeledPoint(1.0, [1.0, 2.0, 0.0]),\n",
    "     LabeledPoint(1.0, [-1.0, 0.0, -0.5])]\n",
    ")  # LabeledPoint(feature, label)\n",
    "\n",
    "# The contingency table is constructed from an RDD of LabeledPoint and used to conduct\n",
    "# the independence test. Returns an array containing the ChiSquaredTestResult for every feature\n",
    "# against the label.\n",
    "featureTestResults = Statistics.chiSqTest(obs)\n",
    "\n",
    "for i, result in enumerate(featureTestResults):\n",
    "    print(\"Column %d:\\n%s\" % (i + 1, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
